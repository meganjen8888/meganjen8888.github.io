 <!DOCTYPE html>
<html>
	<head>
		<style>
		body {
			background-color: coral;
			color: white;
			font-family: Arial, Helvetica, sans-serif;
			}

			h4 {
				align: center;
			}

			div #header {
				color: #83a67e
				height: 15%;
			}


.topnav a {
  float: left;
  color: #f2f2f2;
  text-align: center;
  padding: 14px 16px;
  text-decoration: none;
  font-size: 17px;
}

.topnav a:hover {
  background-color: #ffc6a1;
  color: black;
}

.topnav a.active {
  background-color: #ffc533;
  color: black;
}
			
		</style>
		<title>Computer Vision for Weapon Safety</title>
		<script type = "text/javascript">
		window.onload = function () {
  
  var questionArea = document.getElementsByClassName('questions')[0],
      answerArea   = document.getElementsByClassName('answers')[0],
      checker      = document.getElementsByClassName('checker')[0],
      current      = 0,
  
      allQuestions = {
        'Which machine helps detect contraband in security checks?':['X-rays', 'Cameras', 'Computers', 0],
        
        'Which method is used to increase speed of detection?':['CNN', 'Fast RCNN' , 'Anchors', 1],
        
        'Which of the following was a result of computer vision of weapon detection?':['Increased precision', 'Improved mental state of workers', 'Automatic scanning', 0],
	 
	'Which part will the computer vision require manual work?':['Scanning for contraband', 'Judging and making decisions', 'Alerting the passenger upon finding contraband', 1],
	      
	'What is the first step in the flow of object detection?':['Object Tracking', 'Object Recognition', 'Dataset creation and training', 'Object Detection', 2],
	  	    
  	'What does fast RCNN use to generate region proposals?':['Selective Search', 'X-ray images', 'Anchors', 0],
	      
	'What are anchors ranked by?':['Fast RCNN','CNN','RPN Network', 2],

	'What are one of the two main components of the CCTV surveilance system?':['Operators','RPN Network','Anchors', 0]
      };
      
  function loadQuestion(curr) {
  
    var question = Object.keys(allQuestions)[curr];
    
    questionArea.innerHTML = '';
    questionArea.innerHTML = question;    
  }
  
  function loadAnswers(curr) {
  
    var answers = allQuestions[Object.keys(allQuestions)[curr]];
    
    answerArea.innerHTML = '';
    
    for (var i = 0; i < answers.length -1; i += 1) {
      var createDiv = document.createElement('div'),
          text = document.createTextNode(answers[i]);
      
      createDiv.appendChild(text);      
      createDiv.addEventListener("click", checkAnswer(i, answers));
      
      
      answerArea.appendChild(createDiv);
    }
  }
  
  function checkAnswer(i, arr) {
    
    return function () {
      var givenAnswer = i,
          correctAnswer = arr[arr.length-1];
      
      if (givenAnswer === correctAnswer) {
        addChecker(true);             
      } else {
        addChecker(false);                        
      }
      
      if (current < Object.keys(allQuestions).length -1) {
        current += 1;
        
        loadQuestion(current);
        loadAnswers(current);
      } else {
        questionArea.innerHTML = 'Done';
        answerArea.innerHTML = '';
      }
                              
    };
  }
  
  function addChecker(bool) {
  // This function adds a div element to the page
  // Used to see if it was correct or false
  
    var createDiv = document.createElement('div'),
        txt       = document.createTextNode(current + 1);
    
    createDiv.appendChild(txt);
    
    if (bool) {    
      x=document.getElementsByClassName("checker");  // Find the elements
    for(var i = 0; i < x.length; i++){
    x[i].innerText="Correct!";    // Change the content
    }
    } else {
	x=document.getElementsByClassName("checker");  // Find the elements
    for(var i = 0; i < x.length; i++){
    x[i].innerText="Incorrect...";    // Change the content
    }    
    }
  }
  
  
  // Start the quiz right away
  loadQuestion(current);
  loadAnswers(current);
  
};
		</script>
	</head>
	<body>

		<div class="topnav">
  <a class="active" href="../main_problem.html">Main Problem</a>
  <a href="../introduction.html">Introduction</a>
  <a href="../similar_projects.html">Similar Projects</a>
  <a href="../parts.html">Parts Used</a>
  <a href="../pos_results.html">Positive Results</a>
  <a href="../challenges.html">Challenges</a>
  <a href="../future.html">How to Improve?</a>
  <a href="../conclusion.html">Conclusion</a>
  <a href="../quiz.html">Quiz</a>
  <a href="../sources.html">Sources</a>
</div>
     <h4> Parts to make the machinery work </h4> 
		One part which was used to make computer vision for weapon detection work was the Fast RCNN model. That model was proposed and based on RCNN. This method does not require candidate frames to be included in the Deep Learning model. However, only certain training images are tested in the model, automatically mapping the coordinates at the feature level and speeding up the detection of the model. The accuracy of Fast RCNN on dataset PASCAL-VOC 2007 had overall decently increased in percentage, therefore increasing the efficiency as well.
		The Faster RCNN algorithm was then introduced, and a module called RPN was designed to make the frames required by the training algorithm. An Anchor was also created to extract candidate frames from RPN at various scales. The ‘RPN + Anchor’ approach in the Faster RCNN replaces the Selective Search approach in the original method, which allows the model to be used efficiently and greatly improves the speed.
	SSD, or Single Shot Detection, is also used. 
		Object detection and tracking methods work with datasets being created, trained, and deployed to object detection algorithms. A suitable detection algorithm is chosen for weapon detection. The method would examine and solve the problem, using various machine-learning models such as not only Region Convolutional Neural Network, but also a method called Single Shot Detection.

		<br>
		<img src="object_detection_1.png"/>
		The fast RCNN model has been used by both security checks and survillence machinery. 
	The CNN and RCNN portion of the project has two networks, one to to create relation proposals and other for network for detection. Selective search approach is used to create region proposals, with the RPN network ranking anchors and region boxes.
	CCTV's GDS has used color-based segmentation and interest point detectors, as well as Harris interest point detectors and FREAK descriptors to detect features.
	Its color based segmentation feature involved k-means clustering algorithms to separate other objects, then apply morphological processing on each object to bridge small gaps and extract boundaries. Interest point features are then extracted and matched with a stored descriptor to find out if the footage object is similar to a gun. It sets off an alarm if the accuracy is over 50%.
		<br>
		<img src="fast_rcnn.png"/>
				The GDS also uses system initialization, which puts stored interest point descriptors together with extracted interest point features. The system also uses Harris interest point detector and FREAK to compare images, and preprocessing to remove images from the image during transmission of the video, via a median filter. Image resizing is used to process the images in the system.
		<br>
		FREAK is a keypoint descriptor which is inspired by the vision of the human visual system. A sampling pattern is part of the cascade's computation of binary strings by comparing image features. It is also faster and more accurate than other keypoint descriptors. The binary representation is used for dimensionality reduction.
		<br>
		It can also manipulate smoothing of the input image with Gaussian kernel for noise suppression. The binary descriptor F is made by thresholding the comparison between receptive fields with their Gaussian kernel. It's also created by Difference of Gaussians.
		<br>
		Morphological closing is calculated by having the output of closing, being the erosion of image with structuring element followed by dilation with the structuring element. The boundary is obtained by subtracting the erosion of image output from the original image. Here are the equations: <br>
		<img src="equations.png"/>
		<br>
	Ic is the output of closing, I is the original image, SE is the structuring element, and B is the boundary of image.
		<br>
		The Harris detector is useful for detecting weapons in security footage since it is constant to geometric transformation, illumination change, and noise. Here is its equation, where w(x,y) is the Gaussian window function centered at (x,y), I(x,y) is the image intensity at (x,y), and I(x+u, y+v) is the image intensity at the window shaft of (u,v) from (x,y).
		<br>
		<img src="harris.png"/>
		<br>
		Matching is used to compare the score between the descriptor between the gun and the blob. Interest point features are used for matching, with the inner texture's variation of object. The variation creates different features for interest points of different images, while the outline would remain constant or make slight changes. Similarity score is used to find out the extent of the object shape and if its similar to a shape of a gun.
		The nearest neighbor ratio algorithm is to calculate the match between two descriptors with the metric sum of square difference. Like so:
		<img src="matching.png"/>
	</body>
	
</html>
